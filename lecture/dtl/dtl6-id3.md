# DTL: ID3 und C4.5

> [!IMPORTANT]
>
> <details open>
>
> <summary><strong>üéØ TL;DR</strong></summary>
>
> Der Entscheidungsbaum-Lernalgorithmus **ID3** nutzt den
> Informationsgehalt f√ºr die Entscheidung bei der Attributwahl: Nimm das
> Attribut, welches einen m√∂glichst hohen Informationsgehalt hat. Oder
> andersherum: W√§hle das Attribut, bei dem die verbleibende mittlere
> Entropie der Trainingsmenge nach der Wahl des Attributs am kleinsten
> ist. Oder noch anders formuliert: Nimm das Attribut, bei dem die
> Differenz zwischen der Entropie der Trainingsmenge (vor der Wahl des
> Attributs) und der verbleibenden mittleren Entropie (nach der Wahl des
> Attributs) am gr√∂√üten ist (die Differenz nennt man auch ‚Äú*Information
> Gain*‚Äù). Die Trainingsmenge wird entsprechend der Auspr√§gung in Bezug
> auf das eben gew√§hlte Merkmal aufgeteilt und an die Kinder des Knotens
> weiter gereicht; dort wird der Baum rekursiv weiter aufgebaut.
>
> Durch eine Normierung des *Information Gain* kann eine Verbesserung in
> Bezug auf mehrwertige Attribute erreicht werden, dies f√ºhrt zum
> Algorithmus **C4.5**.
> </details>

> [!TIP]
>
> <details open>
>
> <summary><strong>üé¶ Videos</strong></summary>
>
> - [VL ID3 und C4.5](https://youtu.be/Yo1cmeS6BK8)
>
> </details>

## Wie Attribute w√§hlen?

Erinnerung: CAL2/CAL3

- Zyklische Iteration durch die Trainingsmenge
- Ausschlie√ülich aktuelles Objekt betrachtet
- Reihenfolge der ‚Äúrichtigen‚Äù Attributwahl bei Verzweigung unklar

=\> Betrachte stattdessen die **komplette** Trainingsmenge!

## Erinnerung Entropie: Ma√ü f√ºr die Unsicherheit

- Entropie $`H(S)`$ der Trainingsmenge $`S`$: relative H√§ufigkeit der
  Klassen z√§hlen

- Mittlere Entropie nach Betrachtung von Attribut $`A`$

``` math
    R(S, A) = \sum_{v \in \mathop{\text{Values}}(A)} \frac{|S_v|}{|S|} H(S_v)
```

- Informationsgewinn durch Betrachtung von Attribut $`A`$

``` math
\begin{eqnarray}
    \mathop{\text{Gain}}(S, A) &=& H(S) - R(S, A)\\[5pt]
                            &=& H(S) - \sum_{v \in \mathop{\text{Values}}(A)} \frac{|S_v|}{|S|} H(S_v)
\end{eqnarray}
```

$`R(S,A)`$ ist die Unsicherheit/n√∂tige Bits nach Auswahl von Attribut A.
Je kleiner $`R(S,A)`$, um so kleiner die **verbleibende Unsicherheit**
bzw. um so kleiner die Anzahl der n√∂tigen Bits zur Darstellung der
partitionierten Trainingsmenge **nach** Betrachtung von Attribut $`A`$ ‚Ä¶

=\> Je kleiner $`R(S,A)`$, um so gr√∂√üer der Informationsgewinn

## Informationsgewinn: Kriterium zur Auswahl von Attributen

1.  Informationsgewinn f√ºr alle Attribute berechnen
2.  Nehme Attribut mit gr√∂√ütem Informationsgewinn als n√§chsten Test

| Nr. | $`x_1`$ | $`x_2`$ | $`x_3`$ | $`k`$ |
|-----|---------|---------|---------|-------|
| 1   | 0       | 0       | 0       | A     |
| 2   | 1       | 0       | 2       | A     |
| 3   | 0       | 1       | 1       | A     |
| 4   | 1       | 1       | 0       | B     |
| 5   | 0       | 1       | 1       | B     |
| 6   | 0       | 1       | 0       | A     |

$`H(S) = 0.92 \mathop{\text{Bit}}`$

``` math
\begin{eqnarray}
\mathop{\text{Gain}}(S, x_1) &=& 0.92 - 0.87 = 0.05 \mathop{\text{Bit}}\\
\mathop{\text{Gain}}(S, x_2) &=& 0.92 - 2/6  \cdot 0 - 4/6 \cdot 1\\
                             &=& 0.25 \mathop{\text{Bit}}\\
\mathop{\text{Gain}}(S, x_3) &=& 0.92 - 3/6 \cdot 0.92 - 2/6 \cdot 1 - 1/6 \cdot 0\\
                             &=& 0.13 \mathop{\text{Bit}}
\end{eqnarray}
```

Informationsgewinn f√ºr $`x_2`$ am h√∂chsten =\> w√§hle $`x_2`$ als
n√§chsten Test

## Entscheidungsbaumlerner ID3 (Quinlan, 1986)

``` python
def ID3(examples, attr, default):
    # Abbruchbedingungen
    if examples.isEmpty():  return default
    if examples.each(class == A):  return A  # all examples have same class
    if attr.isEmpty():  return examples.MajorityValue()

    # Baum mit neuem Test erweitern
    test = MaxInformationGain(examples, attr)
    tree = new DecisionTree(test)
    m = examples.MajorityValue()
    for v_i in test:
        ex_i = examples.select(test == v_i)
        st = ID3(ex_i, attr - test, m)
        tree.addBranch(label=v_i, subtree=st)
    return tree
```

Russell und Norvig ([2021](#ref-Russell2021)): Man erh√§lt aus dem
‚ÄúLearn-Decision-Tree‚Äù-Algorithmus ([Russell und Norvig 2021,
678](#ref-Russell2021), Fig. 19.5) den hier vorgestellten
ID3-Algorithmus, wenn man die Funktion
$`\mathop{\text{Importance}}(a, examples)`$ als
$`\mathop{\text{InformationGain}}(examples, attr)`$ implementiert/nutzt.

**Hinweis**: Mit der Zeile `if examples.each(class == A):  return A`
soll ausgedr√ºckt werden, dass alle ankommenden Trainingsbeispiele die
selbe Klasse haben und dass diese dann als Ergebnis zur√ºckgeliefert
wird. Das ‚Äú`A`‚Äù steht im obigen Algorithmus nur symbolisch f√ºr die selbe
Klasse! Es kann also auch ein anderes Klassensymbol als ‚Äú`A`‚Äù sein ‚Ä¶

### Beispiel ID3

| Nr. | $`x_1`$ | $`x_2`$ | $`x_3`$ | $`k`$ |
|-----|---------|---------|---------|-------|
| 1   | 0       | 0       | 0       | A     |
| 2   | 1       | 0       | 2       | A     |
| 3   | 0       | 1       | 1       | A     |
| 4   | 1       | 1       | 0       | B     |
| 5   | 0       | 1       | 1       | B     |
| 6   | 0       | 1       | 0       | A     |

- $`x2`$ h√∂chsten Information Gain
- $`x2=0`$ =\> Beispiele 1,2 =\> A
- $`x2=1`$ =\> Beispiele 3,4,5,6 =\> Information Gain berechnen, weiter
  teilen und verzweigen

## Beobachtung: $`\mathop{\text{Gain}}`$ ist bei mehrwertigen Attributen h√∂her

- Faire M√ºnze:
  - Entropie =
    $`H(\mathop{\text{Fair}}) = -(0.5 \log_2 0.5 + 0.5 \log_2 0.5) = 1 \mathop{\text{Bit}}`$

<!-- -->

- 4-seitiger W√ºrfel:
  - Entropie =
    $`H(\mathop{\text{Dice}}) = -4\cdot(0.25 \log_2 0.25) = 2 \mathop{\text{Bit}}`$

=\> $`\mathop{\text{Gain}}`$ ist bei mehrwertigen Attributen h√∂her

Damit w√ºrden Attribute bei der Wahl bevorzugt, nur weil sie mehr
Auspr√§gungen haben als andere.

*Anmerkung*: Im obigen Beispiel wurde einfach die Entropie f√ºr zwei
‚ÄúAttribute‚Äù mit unterschiedlich vielen Auspr√§gungen betrachtet, das ist
nat√ºrlich kein $`\mathop{\text{Gain}}(S, A)`$. Aber es sollte deutlich
machen, dass Merkmale mit mehr Auspr√§gungen bei der Berechnung des Gain
f√ºr eine Trainingsmenge einfach wegen der gr√∂√üeren Anzahl an
Auspr√§gungen rechnerisch bevorzugt w√ºrden.

## C4.5 als Verbesserung zu ID3

Normierter Informationsgewinn:
$`\mathop{\text{Gain}}(S, A) \cdot \mathop{\text{Normalisation}}(A)`$

``` math
    \mathop{\text{Normalisation}}(A) = \frac{1}{
        \sum_{v \in \mathop{\text{Values}}(A)} p_v \log_2 \frac{1}{p_v}
    }
```

C4.5 kann zus√§tzlich u.a. auch noch mit kontinuierlichen Attributen
umgehen, vgl.
[en.wikipedia.org/wiki/C4.5_algorithm](https://en.wikipedia.org/wiki/C4.5_algorithm).

In einem [Paper](http://www.cs.umd.edu/~samir/498/10Algorithms-08.pdf)
([DOI
10.1007/s10115-007-0114-2](https://doi.org/10.1007/s10115-007-0114-2))
wurde der Algorithmus zu den ‚ÄúTop 10 algorithms in data mining‚Äù
ausgew√§hlt.

Im Wikipedia-Artikel [Information
Gain](https://en.wikipedia.org/wiki/Decision_tree_learning#Information_gain)
finden Sie weitere Informationen zum ‚ÄúInformationsgewinn‚Äù (*Information
Gain*).

Ein anderer, relativ √§hnlich arbeitender Entscheidungsbaumlerner ist der
[CART (Classification And Regression
Tree)](https://en.wikipedia.org/wiki/Decision_tree_learning)-Algorithmus,
wobei der Begriff ‚ÄúCART‚Äù allerdings oft auch einfach allgemein f√ºr
‚ÄúEntscheidungsbaumlerner‚Äù genutzt wird.

Hierzu drei lesenswerte Blog-Eintr√§ge:

- [Deep dive into the basics of Gini Impurity in Decision Trees with
  math
  Intuition](https://medium.com/poli-data/deep-dive-into-the-basics-of-gini-impurity-in-decision-trees-with-math-intuition-46c721d4aaec)
- [Decision Trees,
  Explained](https://towardsdatascience.com/decision-trees-explained-d7678c43a59e)
- [Decision Tree Algorithm With Hands-On
  Example](https://medium.datadriveninvestor.com/decision-tree-algorithm-with-hands-on-example-e6c2afb40d38)

## Beispiele zur Normierung bei C4.5

- Faire M√ºnze:
  - Entropie =
    $`H(\mathop{\text{Fair}}) = -(0.5 \log_2 0.5 + 0.5 \log_2 0.5) = 1 \mathop{\text{Bit}}`$
  - Normierung:
    $`1/(0.5 \log_2 (1/0.5) + 0.5 \log_2 (1/0.5)) = 1/(0.5 \cdot 1 + 0.5 \cdot 1) = 1`$
  - Normierter Informationsgewinn:
    $`\mathop{\text{Gain}}(S, A) \cdot \mathop{\text{Normalisation}}(A) = 1 \mathop{\text{Bit}} \cdot 1 = 1 \mathop{\text{Bit}}`$

<!-- -->

- 4-seitiger W√ºrfel:
  - Entropie =
    $`H(\mathop{\text{Dice}}) = -4\cdot(0.25 \log_2 0.25) = 2 \mathop{\text{Bit}}`$
  - Normierung:
    $`1/(4\cdot 0.25 \log_2 (1/0.25)) = 1/(4\cdot 0.25 \cdot 2) = 0.5`$
  - Normierter Informationsgewinn:
    $`\mathop{\text{Gain}}(S, A) \cdot \mathop{\text{Normalisation}}(A) = 2 \mathop{\text{Bit}} \cdot 0.5 = 1 \mathop{\text{Bit}}`$

=\> Normierung sorgt f√ºr fairen Vergleich der Attribute

*Anmerkung*: Auch hier ist die Entropie nat√ºrlich kein
$`\mathop{\text{Gain}}(S, A)`$. Das Beispiel soll nur √ºbersichtlich
deutlich machen, dass der ‚ÄúVorteil‚Äù von Attributen mit mehr Auspr√§gungen
durch die Normierung in C4.5 aufgehoben wird.

## Wrap-Up

- Entscheidungsbaumlerner **ID3**
  - Nutze *Information Gain* zur Auswahl des n√§chsten Attributs
  - Teile die Trainingsmenge entsprechend auf (‚Äúnach unten hin‚Äù)
- Verbesserung durch Normierung des *Information Gain*: **C4.5**

## üìñ Zum Nachlesen

- Ertel ([2025](#ref-Ertel2025)): Entscheidungsb√§ume: Abschnitt 8.4
- Russell und Norvig ([2021](#ref-Russell2021)): Entscheidungsb√§ume:
  Abschnitt 19.3
- Mitchell ([2010](#ref-Mitchell2010)): ID3: Kapitel 3

> [!NOTE]
>
> <details>
>
> <summary><strong>‚úÖ Lernziele</strong></summary>
>
> - k3: Ich kann die Entscheidungsbaumalgorithmen ID3 und C4.5 auf
>   konkrete Daten anwenden.
>
> </details>

> [!TIP]
>
> <details>
>
> <summary><strong>üèÖ Challenges</strong></summary>
>
> **Games: Behaviour Trees**
>
> In einem Dungeon-Crawler wurden √ºber mehrere Spiele Daten f√ºr die
> Aktionen eines Monsters aufgezeichnet:
>
> | Nr. | Distanz | HP      | Mana   | Aktion    |
> |:----|:--------|:--------|:-------|:----------|
> | 01  | nah     | niedrig | genug  | heilen    |
> | 02  | fern    | niedrig | gering | fliehen   |
> | 03  | nah     | hoch    | gering | angreifen |
> | 04  | nah     | hoch    | genug  | angreifen |
> | 05  | mittel  | mittel  | genug  | angreifen |
> | 06  | fern    | mittel  | gering | fliehen   |
>
> Trainieren Sie mit diesen Daten einen Entscheidungsbaum als *Behaviour
> Tree* f√ºr das Monster, so dass es in einer konkreten Spielsituation
> von nun an die optimale Entscheidung treffen kann. Nutzen Sie daf√ºr
> ID3.
>
> **Textklassifikation**
>
> Betrachten Sie die folgenden Aussagen:
>
> > - Patient A hat weder Husten noch Fieber und ist gesund.
> > - Patient B hat Husten, aber kein Fieber und ist gesund.
> > - Patient C hat keinen Husten, aber Fieber. Er ist krank.
> > - Patient D hat Husten und kein Fieber und ist krank.
> > - Patient E hat Husten und Fieber. Er ist krank.
>
> Aufgaben:
>
> 1.  Trainieren Sie auf diesem Datensatz einen Klassifikator mit ID3.
> 2.  Ist Patient F krank? Er hat Husten, aber kein Fieber.
>
> </details>

------------------------------------------------------------------------

> [!NOTE]
>
> <details>
>
> <summary><strong>üëÄ Quellen</strong></summary>
>
> <div id="refs" class="references csl-bib-body hanging-indent">
>
> <div id="ref-Ertel2025" class="csl-entry">
>
> Ertel, W. 2025. *Grundkurs K√ºnstliche Intelligenz*. 6th edition.
> Springer Vieweg Wiesbaden.
> <https://doi.org/10.1007/978-3-658-44955-1>.
>
> </div>
>
> <div id="ref-Mitchell2010" class="csl-entry">
>
> Mitchell, T. 2010. *Machine Learning*. McGraw-Hill.
>
> </div>
>
> <div id="ref-Russell2021" class="csl-entry">
>
> Russell, S., und P. Norvig. 2021. *Artificial Intelligence: A Modern
> Approach*. 4th Edition. Pearson. <http://aima.cs.berkeley.edu>.
>
> </div>
>
> </div>
>
> </details>

------------------------------------------------------------------------

<img src="https://licensebuttons.net/l/by-sa/4.0/88x31.png" width="10%">

Unless otherwise noted, this work is licensed under CC BY-SA 4.0.

<blockquote><p><sup><sub><strong>Last modified:</strong> 135402a (lecture: improve wording in challenge (DTL), 2025-11-02)<br></sub></sup></p></blockquote>
