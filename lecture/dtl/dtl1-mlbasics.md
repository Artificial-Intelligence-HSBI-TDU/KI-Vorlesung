# DTL: Machine Learning 101

> [!IMPORTANT]
>
> <details open>
>
> <summary><strong>ğŸ¯ TL;DR</strong></summary>
>
> Lernen wird in der KI oft als VerhaltensÃ¤nderung (eines Systems)
> aufgefasst. Dabei soll eine GÃ¼tefunktion optimiert werden.
>
> Je nach verfÃ¼gbarem Feedback eines â€œLehrersâ€ werden typischerweise
> drei Arten von Lernen unterschieden: Ãœberwachtes Lernen, UnÃ¼berwachtes
> Lernen, Reinforcement Lernen. Dabei stellt der Lehrer beim Ã¼berwachten
> Lernen Trainingsbeispiele plus eine Vorgabe (Klasse, Funktionswert)
> zur VerfÃ¼gung, wÃ¤hrend beim unÃ¼berwachten Lernen nur die
> Trainingsbeispiele bereitgestellt werden und der Algorithmus selbst
> ZusammenhÃ¤nge in den Daten erkennen soll. Beim Reinforcement Learning
> erfolgt das Feedback am Ende einer Kette von Aktionen, d.h. der
> Algorithmus muss diese Bewertung auf die einzelnen Aktionen
> zurÃ¼ckrechnen.
>
> Beim Ã¼berwachten Lernen soll eine Hypothese aufgebaut werden, die der
> echten (zu lernenden) Funktion mÃ¶glichst nahe kommt. Eine konsistente
> Hypothese erklÃ¤rt die Trainingsdaten, eine generalisierende Hypothese
> kann auch unbekannte Daten (die aus der selben Quelle stammen, also
> zum selben Problem gehÃ¶ren) korrekt bewerten. Es wird unterschieden
> zwischen Klassifikation (einige wenige diskrete Label/Klassen, die den
> Trainingsbeispielen zugeordnet sind) und Regression (Lernen eines
> Funktionsverlaufs).
>
> Merkmalsvektoren gruppieren Eigenschaften des Problems bzw. der
> Objekte, d.h. jedes Objekt kann Ã¼ber einen Merkmalsvektor beschrieben
> werden. Trainingsdaten sind ausgewÃ¤hlte Beispielobjekte (durch
> Merkmalsvektoren beschrieben) plus die Vorgabe (Klasse oder
> Funktionswert) vom Lehrer.
> </details>

> [!TIP]
>
> <details open>
>
> <summary><strong>ğŸ¦ Videos</strong></summary>
>
> - [VL Machine Learning 101](https://youtu.be/FliWEXQZhsw)
>
> </details>

## Was ist Lernen?

> VerhaltensÃ¤nderung eines Agenten in Richtung der Optimierung eines
> GÃ¼tefunktionals (Bewertungsfunktion) durch Erfahrung.

## Warum Lernen?

- Nicht alle Situationen vorhersehbar
- Nicht alle Details modellierbar
- LÃ¶sung oder LÃ¶sungsweg unbekannt, nicht explizit programmierbar
- Data Mining: Entdeckung neuen Wissens durch Analyse der Daten
- Selbstanpassende Programme

=\> Lernen wichtige Eigenschaft lebender Wesen :-)

## Learning Agent

<picture><source media="(prefers-color-scheme: light)" srcset="images/learning_light.png"><source media="(prefers-color-scheme: dark)" srcset="images/learning_dark.png"><img src="images/learning.png" width="70%"></picture>

## Feedback wÃ¤hrend des Lernens

- **Ãœberwachtes Lernen**
  - Lernen durch Beobachtung
  - Vorgabe von Beispielen: Ein- und Ausgabewerte

  =\> Regression, Klassifikation

<!-- -->

- **UnÃ¼berwachtes Lernen**
  - Erkennen von Mustern in den Inputdaten, Clustering
  - Kein Feedback (!)

<!-- -->

- **Reinforcement Lernen**
  - Bewertung der Aktionen des Agenten am Ende einer Aktionsfolge

**Beispiel Kleinkind**: Lernen von Klassen/Konzepten durch Beispiele

- Zuerst ist alles â€œKatzeâ€ (Ãœbergeneralisierung)
- Differenzierung durch Feedback der Umwelt; Erkennung unterschiedlicher
  AusprÃ¤gungen

## Beispiel: Kreditrisiko

- Bankkunde beantragt Kredit
- Soll er aus Sicht der Bank den Kredit bekommen?

<!-- -->

- Bankangestellter betrachtet (relevante) Merkmale des Kunden:
  - Alter, Einkommen, sozialer Status
  - Kundenhistorie bei der Bank
  - HÃ¶he des Kredits

<!-- -->

- Bewertung des Kreditrisikos:
  - **Klassifikation**: Guter oder schlechter Kunde (BinÃ¤re
    Entscheidung: 2 Klassen)
  - **Regression**: Vorhersage Gewinn/Verlust fÃ¼r die Bank (HÃ¶he des
    Gewinns/Verlusts interessant)

## Beispiel: Autoreparatur

- **Gegeben**: Eigenschaften eines Autos

  =\> Eigenschaften: AusprÃ¤gungen der Merkmale

<!-- -->

- **Gesucht**: Diagnose und Reparaturanleitung

  =\> Hypothese Ã¼ber den Merkmalen (Funktion $`\mathop{\text{h}}`$)

## Lernen durch Beobachten: Lernen einer Funktion $`\mathop{\text{f}}`$

Funktionsapproximation: Lernen einer Funktion $`\mathop{\text{f}}`$
anhand von Beispielen

- Ein Beispiel ist ein Tupel
  $`(\mathbf{x}, \mathop{\text{f}}(\mathbf{x}))`$, etwa

``` math
(\mathbf{x}, \mathop{\text{f}}(\mathbf{x})) = \left(\begin{array}{ccc}
O & O & X \\
. & X & . \\
X & . & .
\end{array}, +1\right)
```

- Aufgabe: Baue Hypothese $`\mathop{\text{h}}`$ auf, so dass
  $`\mathop{\text{h}} \approx \mathop{\text{f}}`$.
  - Benutze dazu Menge von Beispielen =\> **Trainingsdaten**.

<!-- -->

- Ziele:
  1.  **Konsistente Hypothese**: Ãœbereinstimmung bei Trainingsdaten
  2.  **Generalisierende Hypothese**: Korrekte Vorhersage bei
      unbekannten Daten

*Anmerkung*: Stark vereinfachtes Modell realen Lernens!

## Konstruieren einer konsistenten Hypothese

<picture><source media="(prefers-color-scheme: light)" srcset="images/occams1_light.png"><source media="(prefers-color-scheme: dark)" srcset="images/occams1_dark.png"><img src="images/occams1.png" width="40%"></picture>

Welcher Zusammenhang ist hier dargestellt? Offenbar eine Art
Funktionsverlauf â€¦ Wir haben fÃ¼r einige x-Werte die zugehÃ¶rigen y-Werte
vorgegeben.

## Konstruieren einer konsistenten Hypothese (cnt.)

<picture><source media="(prefers-color-scheme: light)" srcset="images/occams2_light.png"><source media="(prefers-color-scheme: dark)" srcset="images/occams2_dark.png"><img src="images/occams2.png" width="40%"></picture>

Die einfachste Approximation wÃ¤re eine lineare Funktion. Allerdings
werden hierbei einige Werte mehr oder weniger stark nicht korrekt
widergegeben, d.h. man hat einen relativ hohen (Trainings-) Fehler.

## Konstruieren einer konsistenten Hypothese (cnt.)

<picture><source media="(prefers-color-scheme: light)" srcset="images/occams3_light.png"><source media="(prefers-color-scheme: dark)" srcset="images/occams3_dark.png"><img src="images/occams3.png" width="40%"></picture>

Die Hyperbel erklÃ¤rt die Trainingsdaten bis auf den einen Punkt sehr
gut. Die Frage ist, ob dieser eine Punkt zum zu lernenden Zusammenhang
gehÃ¶rt oder ein AusreiÃŸer ist, den man gefahrlos ignorieren kann?

## Konstruieren einer konsistenten Hypothese (cnt.)

<picture><source media="(prefers-color-scheme: light)" srcset="images/occams4_light.png"><source media="(prefers-color-scheme: dark)" srcset="images/occams4_dark.png"><img src="images/occams4.png" width="40%"></picture>

Die grÃ¼ne Hypothese ist von allen bisher gezeigten die komplexeste,
erklÃ¤rt aber alle Datenpunkte. D.h. hier wÃ¤re der Trainingsfehler Null.
Zwischen den Trainingsdaten zeigt das Modell eine â€œglatteâ€
Approximation, d.h. es wird auch neue Daten, die es beim Training nicht
gesehen hat, relativ gut erklÃ¤ren. (Dabei liegt freilich die Annahme
zugrunde, dass alle relevanten Daten in der Trainingsmenge vorhanden
sind, d.h. dass es insbesondere zwischen den Datenpunkten keine
AusreiÃŸer o.Ã¤. gibt.)

## Konstruieren einer konsistenten Hypothese (cnt.)

<picture><source media="(prefers-color-scheme: light)" srcset="images/occams5_light.png"><source media="(prefers-color-scheme: dark)" srcset="images/occams5_dark.png"><img src="images/occams5.png" width="40%"></picture>

Diese Hypothese erklÃ¤rt ebenfalls sÃ¤mtliche Trainingsdaten. Allerdings
schwingt die Funktion zwischen den Daten stark hin und her. Vermutlich
entspricht dies nicht dem zu lernenden Funktionsverlauf. Der
Trainingsfehler wÃ¤re wie bei der deutlich einfacheren Hypthese aus dem
letzten Schritt Null. Der Generalisierungsfehler (sprich die Abweichung,
wenn man das Modell nach Daten zwischen den Trainingspunkten fragt)
dÃ¼rfte erheblich hÃ¶her liegen.

D.h. hier hat das Modell einfach die Trainingsdaten auswendig gelernt,
aber nicht den Zusammenhang zwischen den Daten! Dies ist in der Regel
unerwÃ¼nscht!

## Occamâ€™s Razor

**Bevorzuge die einfachste konsistente Hypothese!**

1.  Wenn es mehrere mÃ¶gliche ErklÃ¤rungen fÃ¼r einen Sachverhalt gibt, ist
    die einfachste ErklÃ¤rung allen anderen vorzuziehen.
2.  Eine ErklÃ¤rung ist â€œeinfachâ€, wenn sie mÃ¶glichst wenige Variablen
    und Annahmen enthÃ¤lt und wenn diese in klaren logischen Beziehungen
    zueinander stehen, aus denen der zu erklÃ¤rende Sachverhalt logisch
    folgt.

## Trainingsdaten und Merkmalsvektoren

Lehrer gibt Beispiele vor: Eingabe $`\mathbf{x}`$ und passende Ausgabe
$`\mathop{\text{f}}(\mathbf{x})`$

- Ausgabe: typischerweise Skalar (Funktionswert oder Klasse) =\>
  Beispiel: Bewertung eines Spielstandes bei TicTacToe

<!-- -->

- Eingabe: (Beschreibung des) Objekt(s) oder Situation, die zur Ausgabe
  gehÃ¶rt =\> Beispiel: Spielstand bei TicTacToe

**Merkmalsvektoren**:

- Zusammenfassen der relevanten Merkmale zu Vektoren

## Beispiel: Schwimmen im See

Beschreibung der Faktoren, wann ich im See schwimmen mÃ¶chte:

1.  Scheint die Sonne?
2.  Wie warm ist das Wasser?
3.  Wie warm ist die Luft?

- Trainingsbeispiel:
  - Eingabe: Merkmalsvektor `(sonnig, warm, warm)`
  - Ausgabe: Klasse `ja`

Dabei wird davon ausgegangen, dass jeder Faktor (jedes Merkmal) an einer
bestimmten Stelle im Merkmalsvektor aufgefÃ¼hrt ist. Beispielsweise
gehÃ¶rt das `sonnig` zur Frage â€œScheint die Sonneâ€, `warm` jeweils zur
Wasser- und zur Lufttemperatur.

Damit hat man in einem Vektor eine Situation komplett beschrieben, d.h.
einen Zustand der Welt mit den relevanten Dingen beschrieben. Diesem
Zustand kann man beispielsweise ein Label (Klasse) verpassen, hier in
diesem Fall â€œja, in dieser Welt mÃ¶chte ich schwimmenâ€.

Die Trainingsmenge baut sich dann beim Ã¼berwachten Lernen aus vielen
solcher Paare (Merkmalsvektor, Klasse) auf, und die Algorithmen sollen
diese Zuordnung lernen, d.h. ein Modell fÃ¼r diese Daten erzeugen,
welches die Daten gut erklÃ¤rt und darÃ¼ber hinaus fÃ¼r neue Daten aus der
selben Datenquelle gute Vorhersagen macht.

## Trainingsdaten â€“ Merkmalsvektoren

**Generell**: Merkmalsvektor fÃ¼r Objekt $`v`$:
``` math
    \mathbf{x}(v) = (x_1, x_2, \ldots, x_n)
```

- $`n`$ Merkmale (Attribute)
- Attribut $`x_t`$ hat $`m_t`$ mÃ¶gliche AusprÃ¤gungen
- AusprÃ¤gung von $`v`$ bzgl. $`x_t`$: $`\quad x_t(v) = i \quad`$ (mit
  $`i = 1 \ldots m_t`$)

*Anmerkung*: Stellen Sie sich den Merkmalsvektor $`\mathbf{x}`$
vielleicht wie einen Konstruktor einer Klasse `x` vor: Die einzelnen
Attribute $`x_t`$ sind die Parameter, aus denen der Merkmalsvektor
aufgebaut ist/wird. Jedes der Attribute hat einen Typ und damit eine
bestimmte Anzahl erlaubter Werte (â€œAusprÃ¤gungenâ€) â€¦

**Trainingsbeispiel**:

- Tupel aus Merkmalsvektor und zugehÃ¶riger Klasse:
  $`\left(\mathbf{x}(v), k\right)`$

## Wrap-Up

- Lernen ist VerhaltensÃ¤nderung, Ziel: Optimierung einer GÃ¼tefunktion
  - Aufbau einer Hypothese, die beobachtete Daten erklÃ¤ren soll
  - Arten: Ãœberwachtes Lernen, UnÃ¼berwachtes Lernen, Reinforcement
    Lernen

<!-- -->

- Merkmalsvektoren gruppieren Eigenschaften des Problems bzw. der
  Objekte
- Trainingsdaten: Beispielobjekte (durch Merkmalsvektoren beschrieben)
  plus Vorgabe vom Lehrer

## ğŸ“– Zum Nachlesen

- Russell und Norvig ([2021](#ref-Russell2021)): Lernen: Abschnitte 19.1
  und 19.2

> [!NOTE]
>
> <details>
>
> <summary><strong>âœ… Lernziele</strong></summary>
>
> - k1: Ich kann den Begriff â€œ(maschinelles) Lernenâ€ definieren und
>   verschiedene Arten unterscheiden
> - k2: Ich kann â€œÃœberwachtes Lernenâ€ erklÃ¤ren: Lernen durch Beobachten
>   (mit Lehrer)
> - k2: Ich kann wichtige Elemente des (maschinellen) Lernens erklÃ¤ren:
>   Merkmalsvektoren, Eigenschaften, AusprÃ¤gung, Objekte, Trainingsmenge
>
> </details>

> [!TIP]
>
> <details>
>
> <summary><strong>ğŸ§© Quizzes</strong></summary>
>
> - [Selbsttest Intro ML
>   (ILIAS)](https://www.hsbi.de/elearning/goto.php?target=tst_1106589&client_id=FH-Bielefeld)
>
> </details>

> [!TIP]
>
> <details>
>
> <summary><strong>ğŸ… Challenges</strong></summary>
>
> **Modellierung**
>
> Sie stehen vor der Entscheidung, ob Sie sich zur Vorbereitung auf die
> Flipped-Classroom-Sitzung noch das Skript anschauen. Welche Attribute
> benÃ¶tigen Sie, um die Situation zu beschreiben?
>
> **Metriken fÃ¼r Klassifikatoren**
>
> Es ist wieder Wahlkampf: Zwei Kandidaten O und M bewerben sich um die
> Kanzlerschaft. Die folgende Tabelle zeigt die PrÃ¤ferenzen von sieben
> WÃ¤hlern.
>
> | Nr. | Alter      | Einkommen | Bildung  | Kandidat | Vorhersage |
> |:----|:-----------|:----------|:---------|:---------|:-----------|
> | 1   | $`\ge 35`$ | hoch      | Abitur   | O        | O          |
> | 2   | $`< 35`$   | niedrig   | Master   | O        | O          |
> | 3   | $`\ge 35`$ | hoch      | Bachelor | M        | M          |
> | 4   | $`\ge 35`$ | niedrig   | Abitur   | M        | M          |
> | 5   | $`\ge 35`$ | hoch      | Master   | O        | O          |
> | 6   | $`< 35`$   | hoch      | Bachelor | O        | M          |
> | 7   | $`< 35`$   | niedrig   | Abitur   | M        | O          |
>
> Auf diesem Datensatz wurde ein Klassifikator trainiert, die
> Trainingsergebnisse sind in der Tabelle unter â€œVorhersageâ€ angegeben.
>
> Bewerten Sie den Klassifikator.
> </details>

------------------------------------------------------------------------

> [!NOTE]
>
> <details>
>
> <summary><strong>ğŸ‘€ Quellen</strong></summary>
>
> <div id="refs" class="references csl-bib-body hanging-indent">
>
> <div id="ref-Russell2021" class="csl-entry">
>
> Russell, S., und P. Norvig. 2021. *Artificial Intelligence: A Modern
> Approach*. 4th Edition. Pearson. <http://aima.cs.berkeley.edu>.
>
> </div>
>
> </div>
>
> </details>

------------------------------------------------------------------------

<img src="https://licensebuttons.net/l/by-sa/4.0/88x31.png" width="10%">

Unless otherwise noted, this work is licensed under CC BY-SA 4.0.

<blockquote><p><sup><sub><strong>Last modified:</strong> f393f68 (lecture: fix publishing year of AIMA, 2025-09-27)<br></sub></sup></p></blockquote>
