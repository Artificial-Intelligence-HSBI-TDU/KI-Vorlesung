# EA: Modellierung mit Genetischen Algorithmen

> [!IMPORTANT]
>
> <details open>
>
> <summary><strong>ğŸ¯ TL;DR</strong></summary>
>
> Lokale Suchverfahren: Nur das Ergebnis zÃ¤hlt!
>
> EvolutionÃ¤re Algorithmen sind lokale Suchverfahren, wobei gleichzeitig
> an mehreren Stellen im Problemraum gesucht wird. Sie bedienen sich
> Mechanismen aus der Evolution: Es gibt eine Population von Individuen,
> die jedes das Problem kodieren (â€œvollstÃ¤ndige Zustandsbeschreibungâ€)
> und damit im Laufe der Suche zu einer mÃ¶glichen LÃ¶sung werden kÃ¶nnen.
>
> Die Individuen werden mit Hilfe einer Fitnessfunktion bewertet, wie
> gut sie bereits an das Problem angepasst sind (bzw. wie sehr sie
> bereits der gesuchten LÃ¶sung entsprechen). Ãœber eine
> fitnessproportionale Selektion werden Individuen ausgewÃ¤hlt, aus denen
> mittels Rekombination (auch â€œCrossoverâ€ genannt) neue Individuen mit
> Eigenschaften der Eltern erzeugt werden. Ãœber eine Mutation werden
> dann noch Elemente der neuen Individuen leicht verÃ¤ndert, bevor diese
> zur neuen Population werden â€¦
>
> Durch das Anwenden von Rekombination und Mutation springt man im
> Problemraum umher. Auch wenn als Basis die fitteren (angepassteren)
> Individuen dienen, kann es wie bei allen lokalen Suchverfahren
> vorkommen, dass sich der Algorithmus in lokalen Minima (bzw. lokalen
> Maxima, je nach Richtung der Optimierung) festfrisst.
> </details>

> [!TIP]
>
> <details open>
>
> <summary><strong>ğŸ¦ Videos</strong></summary>
>
> - [VL Modellierung mit EA/GA](https://youtu.be/Sd5AA6LIEOc)
>
> </details>

## EA â€“ Allgemeiner Ablauf

<picture><source media="(prefers-color-scheme: light)" srcset="images/ea_prinz_light.png"><source media="(prefers-color-scheme: dark)" srcset="images/ea_prinz_dark.png"><img src="images/ea_prinz.png" width="60%"></picture>

## Kodierung Individuen

- BinÃ¤re LÃ¶sungsreprÃ¤sentation (Bitstring):
  $`\mathbf{g} = (g_1, \dots, g_m)\in \{ 0,1\}^m`$
  - String gliedert sich in $`n`$ Elemente (mit $`n \le m`$) =\> jedes
    Segment entspricht einer Problemvariablen
  - Dekodierungsfunktion $`\Gamma : \{0,1\}^m \to \mathbb{R}^n`$

  Alle relevanten Aspekte des Problems mÃ¼ssen in die Codierung
  einflieÃŸen!

  Bei ES hat man einen Vektor mit reellen Zahlen, wobei jeder Eintrag
  einen Parameter des Problems darstellt. Eine Dekodierungsfunktion
  benÃ¶tigt man entsprechend nicht.

  Bei der Erzeugung der Startpopulation werden die Individuen
  **zufÃ¤llig** (mit zufÃ¤lligen Werten) initialisiert.

<!-- -->

- Fitnessfunktion $`\Phi`$ ordnet jedem Individuum $`\mathbf{g}_i`$ eine
  reelle Zahl zu:
  - Zielfunktion $`F`$: wie sehr genÃ¼gt ein Individuum bereits dem
    Optimierungproblem
  - Strafterme $`Z_j`$: Anreicherung der Optimierung mit weiteren
    Informationen
  - Gewichte $`w`$: statisch oder dynamisch (AbkÃ¼hlen)

  Die Wahl einer guten Fitnessfunktion ist oft eine Herausforderung,
  aber dennoch wichtig, da damit die Suche gesteuert wird!

``` math
\Phi(\mathbf{g}_i) = F(\Gamma(\mathbf{g}_i)) - w\cdot\sum_j(Z_j(\Gamma(\mathbf{g}_i)))^2
```

## Selektion: Erstelle Matingpool mit $`\mu`$ Individuen

- Fitnessproportionale Selektion (*Roulette Wheel Selection*):
  Auswahlwahrscheinlichkeit fÃ¼r Individuum $`\mathbf{g}_k`$: =\>
  Voraussetzung: positive Fitnesswerte

``` math
p_{sel}(\mathbf{g}_k) = \frac{\Phi(\mathbf{g}_k)}{\sum_j \Phi(\mathbf{g}_j)}
```

- Turnier-Selektion (*Tournament Selection*):
  - TurniergrÃ¶ÃŸe $`\xi`$
  - Turnier: ziehe $`\xi`$ Individuen gleichverteilt (mit ZurÃ¼cklegen!)
    und kopiere fittestes Individuum in den Matingpool
  - FÃ¼hre $`\mu`$ Turniere durch

*Hinweis*: Es gibt noch viele weitere Selektionsmechanismen. Die
vorgestellten sind in der Praxis am gebrÃ¤uchlichsten.

Ãœber die Selektion wird der sogenannte â€œSelektionsdruckâ€ aufgebaut: Wie
gut muss ein Individuum sein (im Vergleich zu den restlichen Individuen
in der Population), damit es eine Chance zur Reproduktion erhÃ¤lt? DÃ¼rfen
sich nur die â€œGutenâ€ fortpflanzen, oder erhalten auch die â€œSchlechtenâ€
eine gewisse Chance?

Da jedes Individuum einen Punkt im Suchraum darstellt, beeinflusst die
Wahl der Selektion die Geschwindigkeit der Suche, begÃ¼nstigt u.U. aber
auch ein eventuelles Festfahren in lokalen Minima. Dies kann
beispielsweise geschehen, wenn immer nur die â€œGutenâ€ selektiert werden,
aber die â€œGutenâ€ der Population sich in der NÃ¤he eines lokalen Minimums
befinden. Dann werden auch die Nachfolger sich wieder dort aufhalten.

## Crossover: Erzeuge zwei Nachkommen aus zwei Eltern

Festlegung der Crossover-Wahrscheinlichkeit $`p_{cross}`$ (typisch:
$`p_{cross} \ge 0.6`$)

1.  Selektiere Eltern $`\mathbf{g}_a`$ und $`\mathbf{g}_b`$
    **gleichverteilt** aus Matingpool

<!-- -->

1.  Zufallsexperiment:
    - mit $`1-p_{cross}`$: Kinder identisch zu Eltern (kein Crossover)
    - mit $`p_{cross}`$: Crossover mit $`\mathbf{g}_a`$ und
      $`\mathbf{g}_b`$
      - Ziehe $`i`$ gleichverteilt mit $`1 < i < m`$
      - Kinder aus $`\mathbf{g}_a`$ und $`\mathbf{g}_b`$ zusammenbauen:
        und

      =\> Trenne Eltern an gleicher Stelle auf, vertausche Bestandteile

``` math
\mathbf{g}_c = (g_{a,1}, \dots, g_{a,i}, \; g_{b,{i+1}}, \dots, g_{b,m})
```

``` math
\mathbf{g}_d = (g_{b,1}, \dots, g_{b,i}, \; g_{a,{i+1}}, \dots, g_{a,m})
```

1.  Gehe zu Schritt 1, bis insg. $`\mu`$ Nachkommen

*Anmerkung*: Die Eltern werden jeweils in die Ausgangsmenge
zurÃ¼ckgelegt.

Mit einer kleinen Wahrscheinlichkeit sind die Kinder also identisch zu
den Eltern. Dies ist im Sinne der lokalen Suche wichtig, um bereits
erreichte gute Positionen im Suchraum nicht zu verlieren: Es kÃ¶nnte
sein, dass die Nachfolger alle schlechter sind â€¦

Varianten: $`N`$-Punkt-Crossover, Shuffle-Crossover

Bei ES wird parameterweise gekreuzt. Dabei gibt es verschiedene
MÃ¶glichkeiten: Ãœbernahme eines Parameters von einem Elternteil,
Verrechnen (beispielsweise Mitteln) der Werte beider Eltern, â€¦ Bei ES
heiÃŸt â€œCrossoverâ€ deshalb oft â€œRekombinationâ€.

## Mutation

- Mutationswahrscheinlichkeit $`p_{mut}`$ (typische Werte:
  $`p_{mut} = 0.01`$ oder $`p_{mut} = 0.001`$)

<!-- -->

- FÃ¼r alle Individuen:
  - Mutiere jedes Gen eines Individuums mit $`p_{mut}`$:

    =\>$`\chi_i`$ gleichverteilte Zufallsvariable (Intervall $`[0,1]`$),
    fÃ¼r jedes Bit $`g_i`$ neu bestimmen

``` math
g_i^{(t+1)} = \left\{
\begin{array}{rll}
    \neg & g_i^{(t)} & \text{ falls } \chi_i \le p_{mut}\\[5pt]
    & g_i^{(t)} & \text{ sonst }
\end{array}
\right.
```

*Anmerkung*: Die optimale Mutationsrate $`p_{mut}^*`$ ist von LÃ¤nge
$`m`$ des Bitstrings abhÃ¤ngig; annÃ¤herbar durch
$`p_{mut}^* \approx 1/m`$.

Die beim Crossover erstellten Nachfolger liegen im Suchraum in der NÃ¤he
der Eltern. Durch die Mutationsrate bestimmt man, ob und wie weit sich
ein Kind entfernen kann. Dies entspricht dem Bild des â€œSchÃ¼ttelnsâ€ der
Zustandslandschaft.

Bei ES unterscheidet man Mutationswahrscheinlichkeit und Mutationsrate.
Es wird parameterweise mutiert.

## Bewertungskriterien

Vorsicht: Es handelt sich um Zufallsexperimente. Wenn man nicht nur
direkt nach einer LÃ¶sung sucht, sondern beispielsweise
Parametereinstellungen oder die Wahl der Fitnessfunktion fÃ¼r ein Problem
vergleichen will, muss man jeweils mehrere Experimente mit der selben
Einstellung machen und KenngrÃ¶ÃŸen berechnen.

**Geschwindigkeit: AES** *Average Evaluations to a Solution*
``` math
\text{AES } = \frac{\sum\limits_{i \in \text{erfolgreiche LÃ¤ufe}} \text{Generationen von Lauf } i}{\text{Anzahl der erfolgreichen LÃ¤ufe}}
```

Die AES liegt im Intervall $`[0, maxGen]`$.

**LÃ¶sungswahrscheinlichkeit: SR** *Success Rate*
``` math
\text{SR } = \frac{\text{Anzahl der erfolgreichen LÃ¤ufe}}{\text{Anzahl aller LÃ¤ufe}}
```

Die SR liegt im Intervall $`[0, 1]`$.

## Typische LÃ¤ufe

<picture><source media="(prefers-color-scheme: light)" srcset="images/typischerLauf_ritterIII_mG500M15L100_fail_light.png"><source media="(prefers-color-scheme: dark)" srcset="images/typischerLauf_ritterIII_mG500M15L100_fail_dark.png"><img src="images/typischerLauf_ritterIII_mG500M15L100_fail.png" width="60%"></picture>

<picture><source media="(prefers-color-scheme: light)" srcset="images/typischerLauf_ritterIII_mG500M15L100_success_light.png"><source media="(prefers-color-scheme: dark)" srcset="images/typischerLauf_ritterIII_mG500M15L100_success_dark.png"><img src="images/typischerLauf_ritterIII_mG500M15L100_success.png" width="60%"></picture>

- PopulationsgrÃ¶ÃŸe $`\mu=15`$
- Anzahl Nachfahren $`\lambda=100`$
- Abbruch nach $`maxGen=200`$ Generationen

Stochastischer Algorithmus! Ausreichend Wiederholungen durchfÃ¼hren und
mitteln!

*Hinweis*: Die Parameter mÃ¼ssen problemabhÃ¤ngig gewÃ¤hlt werden. Zu hohe
Werte fÃ¼r $`\mu`$ und $`\lambda`$ fÃ¼hren dazu, dass man bei kleinen
Problemen mit hoher Wahrscheinlichkeit bereits am Anfang eine LÃ¶sung
â€œwÃ¼rfeltâ€, also gar kein GA nutzt. Wenn dies allerdings nicht passiert,
sorgt eine hohe PopulationsgrÃ¶ÃŸe dafÃ¼r, dass jeder Schritt sehr lange
dauert. Die Abbruchgrenze ist ebenfalls mit AugenmaÃŸ zu wÃ¤hlen: Ein zu
kleiner Wert sorgt fÃ¼r zu frÃ¼hen Abbruch (keine LÃ¶sung!), ein zu hoher
Wert sorgt beim Festfressen des Algorithmus fÃ¼r eine unnÃ¶tige weitere
â€œSucheâ€ â€¦

## Wrap-Up

Lokale Suchverfahren: Nur das Ergebnis zÃ¤hlt!

- EvolutionÃ¤re Algorithmen:
  - Begriffe: Individuum, Population, Kodierung
  - Operationen: Selektion, Rekombination, Mutation
  - Bewertung mit Fitnessfunktion

## ğŸ“– Zum Nachlesen

- Russell und Norvig ([2021](#ref-Russell2021)): GA: Abschnitt 4.1.4
- Weicker ([2015](#ref-Weicker2015))

> [!NOTE]
>
> <details>
>
> <summary><strong>âœ… Lernziele</strong></summary>
>
> - k3: Ich kann GA anwenden, insbesondere fÃ¼r ein Beispiel passende
>   Kodierung, Fitnessfunktion, Operatoren und Auswertung formulieren
>   und den Ablauf erklÃ¤ren
>
> </details>

> [!TIP]
>
> <details>
>
> <summary><strong>ğŸ§© Quizzes</strong></summary>
>
> - [Selbsttest EA/GA
>   (ILIAS)](https://www.hsbi.de/elearning/goto.php?target=tst_1106580&client_id=FH-Bielefeld)
>
> </details>

> [!TIP]
>
> <details>
>
> <summary><strong>ğŸ… Challenges</strong></summary>
>
> **Sudoku**
>
> Ein $`9 \times 9`$-*Sudoku*-RÃ¤tsel soll mit einem GA gelÃ¶st werden.
>
> Geben Sie fÃ¼r dieses Problem jeweils eine geeignete **Kodierung** der
> Individuen, passende Operatoren (**Crossover**, **Mutation**) und eine
> geeignete **Fitnessfunktion** an, damit das Problem mit einem GA
> gelÃ¶st werden kann. BegrÃ¼nden Sie Ihre Wahl!
>
> Was wÃ¼rden Sie noch benÃ¶tigen, um das Probleme mit Simulated Annealing
> lÃ¶sen zu kÃ¶nnen?
>
> **Travelling Salesman Problem**
>
> Das *Travelling Salesman Problem* fÃ¼r 10 StÃ¤dte, d.h. das Finden der
> kÃ¼rzesten Route zwischen 10 StÃ¤dten, soll mit einem GA gelÃ¶st werden.
>
> Geben Sie fÃ¼r dieses Problem jeweils eine geeignete **Kodierung** der
> Individuen, passende Operatoren (**Crossover**, **Mutation**) und eine
> geeignete **Fitnessfunktion** an, damit das Problem mit einem GA
> gelÃ¶st werden kann. BegrÃ¼nden Sie Ihre Wahl!
>
> Was wÃ¼rden Sie noch benÃ¶tigen, um das Probleme mit Simulated Annealing
> lÃ¶sen zu kÃ¶nnen?
> </details>

------------------------------------------------------------------------

> [!NOTE]
>
> <details>
>
> <summary><strong>ğŸ‘€ Quellen</strong></summary>
>
> <div id="refs" class="references csl-bib-body hanging-indent">
>
> <div id="ref-Russell2021" class="csl-entry">
>
> Russell, S., und P. Norvig. 2021. *Artificial Intelligence: A Modern
> Approach*. 4th Edition. Pearson. <http://aima.cs.berkeley.edu>.
>
> </div>
>
> <div id="ref-Weicker2015" class="csl-entry">
>
> Weicker, K. 2015. *EvolutionÃ¤re Algorithmen*. 3rd edition. Springer
> Vieweg Wiesbaden. <https://doi.org/10.1007/978-3-658-09958-9>.
>
> </div>
>
> </div>
>
> </details>

------------------------------------------------------------------------

<img src="https://licensebuttons.net/l/by-sa/4.0/88x31.png" width="10%">

Unless otherwise noted, this work is licensed under CC BY-SA 4.0.

<blockquote><p><sup><sub><strong>Last modified:</strong> 2a2d1ce (lecture: update readings for EA/GA, 2025-10-23)<br></sub></sup></p></blockquote>
